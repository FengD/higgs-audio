谢谢你，斯拉瓦。那么，我的标题是英文的，但我会讲法语。反正他们是这么要求的。

那么，机器如何才能达到人类智能呢？正如斯拉瓦所说，正如我今天早上在荣誉博士学位授予仪式上提到的，我受到这本书的启发，开始研究机器学习。这本书的法文译本，实际上也有英文版，是 Jean Piaget 和 Noam Chomsky 之间一场辩论的记录或转录，涉及两组研究人员，一方主张语言是先天的，另一方主张语言是后天习得的。

他曾在麻省理工学院任教，但曾在 Jean Piaget 实验室待过一段时间，并研究了当时相对简单的学习模型，特别是感知机。他赞美感知机，对 Chomsky 一方的科学家说，即使是这种非常简单的机器也能够学习奇怪的复杂概念。深入研究文献，因为我对这种能够学习的机器的故事产生了浓厚的兴趣，我发现同一位 Simon Papert 在一九六九年与 Marvin Minsky 合著了一本书，这本书实际上扼杀了相关研究领域，也就是说，由于这本书，神经网络研究在六十年代末变得禁忌。所以，十年后他出现了，赞美感知机，而他曾是导致其衰落的因素之一。这有点自相矛盾，但这并没有阻止我深入研究文献，我意识到它有点过时了，有一些日本作者继续在这方面工作。然后我在研究生学习的早期发现，实际上有一小部分人，主要在美国、英国、德国和日本的一些地方，他们正在研究神经网络。特别是两个人，John Hoffield 和 Jeff Hinton，他们几天前获得了诺贝尔物理学奖。他们获得诺贝尔奖的模型现在已经完全不使用了，它们的效果也不是特别好，但他们的论文对这个领域产生了巨大的影响，因为他们正是打破了禁忌，他们帮助使神经网络领域再次被接受或受到尊重。因此，他们促成了对这些模型的新一轮兴趣，这持续了十多年，从八十年代初到九十年代中期，然后我们又经历了另一个神经网络的寒冬，如果你愿意的话，直到二零一零年代初或二零零零年代末。好了，历史就讲到这里。

我们需要像人类一样智能的人工智能。对有些人来说，这令人恐惧，但对另一些人来说，这更是一种希望，一种带来希望的东西。我们需要它的原因是因为未来，可能不会太遥远，我想在座的许多人都会看到，每个人都将与人工智能系统互动，这些助手将与我们同在，一整天，他们将帮助我们完成日常任务，帮助我们解决问题等等。这些系统可能比人类更智能，但它们将为我们服务。也就是说，我们将向它们提问，给它们解决问题的任务，它们将为我们解决，但它们将完成的目标和任务将由人类决定。这有点像，比如说，一个学术实验室主任，公司负责人，或者也许是政治领导人，他们身边有一个随时提供建议的员工团队，这些员工很可能比他们更聪明。嗯，对于学术界的人来说可能不是这样，但对于政治家来说肯定如此。我们不应该因为将被比我们更智能的实体陪伴而感到威胁，实际上，它将倍增我们的智能，放大它。同样，我们不应该因为与比我们更聪明的人一起工作而感到威胁。我不知道你是不是这样，但至少对我来说，我非常习惯与比我更聪明的人一起工作。事实上，我希望只雇用比我更聪明的人。所以就是这样。而且，我们与之互动的这些系统，实际上，需要易于维护，易于驾驶，易于互动，为此，它们需要接近人类智能的智能，可能在能力上更优越，但在定性方面相对相似，以简化我们与它们的沟通。因此，这需要能够理解物理世界的机器，就像我们理解物理世界一样，任何动物，理解物理世界，具有持久记忆的系统，能够规划复杂行动以实现目标的系统，能够推理的系统，以及可控和安全的系统，也就是说，例如，如果我们要求它们去给我们拿咖啡，而另一个人挡住了去咖啡机的路，它们不会践踏那个可怜的人，仅仅为了拿到咖啡机而杀人。好吧，这属于科幻小说的范畴等等。实际上，这个目标与人类价值观对齐的问题并不像有些人所说的那样复杂和无法解决。

那么，这意味着什么呢？这是否意味着采用当前的系统，例如 LLM，或者类似的架构，然后我们就能仅仅通过用更多数据训练这些系统，或者仅仅通过用更多计算能力、更精细的训练等来达到人类级别的智能吗？我对这个问题的回答是绝对不是。LLM 非常有用，非常强大，有很多应用可以开发，但它们本身不会导致达到智能级别的系统。我不用那个专用的缩写，也就是英语中的 AGI，即通用人工智能。我讨厌这个词，因为如果我们用它来指代具有人类智能的系统，那就会造成巨大的误解，因为人类智能根本不是通用的。人类智能是非常专业的。我们有点难以想象人类智能是专业的。但这仅仅是因为我们很难想象我们无法解决的问题。所以 AGI 是一个非常糟糕的名字，所以我更喜欢 HLAI，即 Human Level Intelligence（人类级别智能），或者像我们在 Meta 内部称呼的那样，我们有一个非常好的名字，那就是 AMI。法语是 AMI，英语也是 AMI。这意味着高级机器智能，这更合理。

那么，如何构建智能机器的第一个问题是推理问题。推理是什么意思？它只是系统计算其输出的过程。如果我们有一个神经网络或一个经典的深度学习系统，系统计算其输出的方式是，我们给它一个输入，我们将这些输入传播到系统内部，然后系统产生一个输出。也就是说，它有一个固定的计算步骤数来计算输出。LLM 具有这样的特性：我们给它们一个提示，一个输入，为了生成一个 token，也就是一个词，计算下一个词所需的计算量是固定的。这意味着这些系统无法真正思考。思考意味着在复杂问题上花费更多时间，而不是在简单问题上。我们可以用来让 LLM 花更多时间思考的方法是让它们生成更多的 token，也就是无用的词。还有另一种模型叫做优化推理，它旨在让系统在其输入和输出之间计算一种衡量输入和输出兼容性的量。因此，如果我们有一个输入和一个我们提供给系统的兼容输出，系统会计算一个我们可以称之为能量的数字，这个数字会很小，比如说零。如果我们给它一张大象的图片，并提供“大象”作为输出，它会告诉我们零，因为大象与图片兼容。如果我们给它一张大象的图片，并提供“标签”作为提议的输出，系统给出更高的能量，十。因此，这种类型的系统计算其输出的方式是，我们给它一个输入，然后它在所有可能的输出中寻找一个或多个能使这个数字、这个能量、这个输入和输出之间的兼容性最小化的输出。然后它可以穷尽式地进行这种搜索，如果这是一个连续空间，则使用梯度下降法等。这就是所谓的推理，这是一种本质上比简单地通过神经网络层传播信号更强大的推理方法。从概念上讲，理论上，我们几乎可以将所有问题都归结为优化问题，也就是我所描述的推理类型，但我们不能总是将输出的计算归结为一个固定数量的计算步骤问题，就像神经网络中的前向传播一样。所以它本质上更强大。这与我们目前在 LLM 和大多数 AI 系统中使用的模型完全不同。这种推理技术已用于能够学习的 AI 系统，特别是能够玩国际象棋等游戏的系统，在这种系统中，我们会想象一定数量的未来的场景，关于对手将如何行动。然后，在所有想象的场景中，我们选择最有可能导致胜利的场景。这种通过优化进行推理的想法导致了一种我称之为目标驱动人工智能（Objective Driven AI）的架构，它将使人工智能系统能够解决八十年代和九十年代基于逻辑的经典人工智能系统能够解决的问题，即在可能的解决方案空间中搜索解决方案，这个想法可以追溯到五十年代，但在当前的人工智能模型中有点消失了。因此，我认为通过优化计算输出非常重要。这有点像我们想象的，心理学家称之为系统二的具体体现。在人类或动物的行为中，系统一对应于我们下意识地完成的、不假思索的动作，这些动作有点自动化，我们太习惯于解决它们，以至于不需要思考采取什么行动。而系统二则需要我们的注意力、我们的意识，我们的世界模型，它让我们能够想象一系列行动的结果，从而规划一系列行动。

为了从这些能量函数中捕捉输入和输出之间的依赖关系，我们需要一种好的方式来表示它，这就是我们所说的基于能量的模型，它捕捉变量 x 和 y 之间的依赖关系，比如说图中的这些变量。它们是标量，但可以是任何东西，离散的、连续的、高维的等等。因此，能量函数必须在我们知道它们兼容的 XY 对中取低能量值，因此我们可以假设它们存在于我们将用于训练机器的学习集中。因此，训练这种机器包括改变这个能量函数的参数，它将是一个带有单个标量输出的大型神经网络，标量输出取一个低值，比如说零，或者尽可能低的值，对于在学习过程中呈现的对，也就是在学习集中的 x, y 对，这些对由这里的黑点，黑盘表示。然后，能量函数对于我们不显示的点的取值会更高。这就是训练基于能量的系统变得复杂的地方。如何确保能量函数取更高的值，对于我们不展示的例子。如果所讨论的空间是高维的，则尤其复杂。

在解释如何训练这些基于能量的模型之前，我将简要介绍一下生成模型和 LLM。LLM 是自回归模型，它们被训练来根据左侧的单词预测一个单词。所以训练起来非常容易，我们取一段文本，然后让系统预测所有输入的单词，但是系统不能使用输入，不能简单地将输入复制到输出，因为它只能使用它需要预测的单词左侧的单词。所以实际上它被隐式地训练来预测一个单词序列后面的单词。那么一旦它被训练来预测后面的单词，我们当然可以给它一个文本的开头，这可能是一个问题，然后要求它预测下一个词。然后我们将这个词注入输入，要求它预测第二个词，我们将其注入输入，第三个词，等等。这就是自回归预测，这不是一个新概念，它起源于 Matthew Zalem。但正如我之前所说，没有思考，没有推理，没有规划，没有世界的心理模型。它纯粹是预测下一个 token 或下一个词，训练数据的统计数据。这非常有用，奇怪的是，它仍然相当令人惊叹和智能。如果我们训练一个非常大的神经网络来做这件事，它实际上能够记住大量的场景，因此有时几乎能够解决问题等等。但它也会犯大错误，而且它们无法进行推理。现在，该领域的许多人都在研究推理，Meta、Google、OpenAI 以及其他地方的许多人都在研究推理，还有一些大学实验室也在研究推理。实际上，多年来有一系列文章，特别是亚利桑那州立大学的 Subarao Kambampati 教授，他来自更传统的 AI 领域，他展示了大量实验，表明 LLM 实际上无法进行规划。因此，存在一些 AI 中经典的规划问题。虽然取得了进展，但我们还没有达到目标。认知科学领域的人士表示，LLM 无法进行人类大脑（以及许多动物）能够进行的概括和规划。

那么，如果我们想要构建一个通过优化进行推理的这类模型，我们仍然需要对其进行一些结构化。这是一个关于结构化的想法，它围绕着一个我称之为世界模型的模块构建。架构如这里所示。我们对环境进行观察。这不是整个世界，而是我们可以通过传感器、摄像头等捕捉到的东西。这个输入进入一个感知系统，该系统构建了一个对感知环境的抽象表示，世界最初的状态。显然，今天我正在看这个房间，我对这个房间里的世界状态有一个概念，但当然，这种感知并没有改变我对世界其他地方状态的看法。所以我必须将我对这里世界状态的看法与记忆内容结合起来，记忆内容在人类大脑、哺乳动物大脑的海马体中，它包含着关于世界的知识和信息，并且不会随着当前的感知而改变。所有这些都进入一个世界模型，世界模型的作用是想象代理执行一系列动作后将产生的状态，即预测世界状态。因此，代理想象一系列动作（这里用黄色表示），这些动作被提供给世界模型，世界模型根据想象的动作序列和初始化的状态，世界模型会根据这组动作序列，对世界的未来状态进行预测，或者可能进行多次预测。然后，这个预测的状态会传递给一系列成本函数和目标函数，它们的输出未显示，但只是一个标量。第一个是与任务相关的目标，它会给我们一个低值，如果某个特定任务已完成，则为低值，如果任务未完成，则为高值，然后是另一组目标，即安全防护措施。因此，成本函数确保系统产生的状态序列或动作序列不会危及周围的用户，例如。通过训练或构建这些目标安全措施来确保系统的安全。那么系统的工作方式是，给定一个感知、记忆内容以及对一系列动作的假设，系统会预测结果，将其提供给成本函数，然后通过优化，尝试改变、修改，想象中的行动序列，以使该行动序列同时最小化任务目标和安全目标。因此，这是通过优化进行的推理，但它与一个预测将要发生的世界的心理模型相关联。通常，世界模型无法进行长时间的行动序列并预测将要发生的事情，但我们必须多次迭代我们的世界模型才能预测将会发生什么。所以，想象一个包含两个动作的序列。我们将第一个动作提供给我们的世界模型，它会预测由于第一个动作在不久的将来会发生什么。然后，将第二个动作提供给世界模型，它会多次预测将会发生什么，等等。所以我们实际上会多次预测结果。然后，通过优化，这可以基于反向传播，梯度，但我们还没有谈到学习，只是为了推理，为了计算输出，这可以通过梯度下降或其他组合优化方法来完成。

不幸的是，世界并非完全确定性的，即使它是确定性的，物理学家说，它并非完全可预测，因为它并非完全可观察。而且在所有情况下，它都可能是混沌的，因此很难预测。所以世界模型无法做出精确的预测。因此，可能需要给它所谓的潜在变量，也就是说，我们不知道其值的变量，但我们取其值，要么从分布中采样，要么在集合中循环以产生多个预测，可能发生的事情。由于世界的不确定性，当然，可能会发生许多我们无法预测的事情。但图中表示的所有函数，即所有圆角的函数，都是我们可以计算的确定性函数。它是一个神经网络或类似的东西。我们给它一个输入，它计算输出，只有一个输出。如果我们想让它计算多个输出，我们需要一个潜在变量，我们改变它的值。就这么简单。

人类和动物不会在某个层面上规划一系列行动。也就是说，如果我们要规划从日内瓦到纽约的行程，并决定明天下午到达纽约，就像我即将要做的那样，我们不会每毫秒都以肌肉控制的方式规划从日内瓦到纽约的行程。人类大脑动作的最低级别是肌肉控制。我们无法以肌肉控制的方式，毫秒级地规划从日内瓦到纽约的旅程。我们进行分层规划。我们首先制定一个非常抽象的场景，我们说要去纽约，我需要去机场，然后乘坐飞机去纽约。一个子目标是去机场。我怎么去机场？我需要叫一辆出租车把我送到机场，或者乘坐公共交通工具。假设我乘坐一辆出租车。那么我需要叫出租车，然后我需要走到街上。我怎么走到街上？我需要走到门口，然后走到街上。我怎么走到门口？我需要知道它在哪里，然后我需要一步一步地走。我怎么一步一步地走？我们可以一直往下追溯到肌肉控制的层面。实际上，这个层次结构非常深，直到我们不再需要规划的层面，因为任务太简单了，我们不需要思考，我们可以下意识地完成它们。但是规划是分层的。这个分层规划问题在人工智能领域完全没有解决。如果你是一个考虑攻读人工智能博士学位的学生，试着解决这个问题。这是完全空白的。这并不是说人们没有在这方面努力。这意味着我们不知道如何使用学习技术来做到这一点。如果我们手动构建这些东西，我们知道如何做到。今天大多数机器人使用分层规划，但它们完全是手动完成的。那么如何学习这些呢？如何学习世界模型？如何学习这些目标函数和安全措施？这三个问题基本上没有解决。但我仍然会向您展示一些例子，这些例子表明我们正在取得进展。

事实上，所有这些想法都促成了一种我称之为目标驱动人工智能（Objective Driven AI）或目标驱动架构的智能系统的整体架构。我已经在两年半前发表的一篇文章中描述了这一切的计划，地址在这里。它在 Open Review 上，而不是 Archive 上。在 Open Review 上，因为你可以发表评论并告诉我我是否错了。我会很高兴你告诉我这些，这样可以避免我浪费时间，也许可以修正这篇文章。所以那是在 ChatGPT 和所有这些之前，但计划没有改变。所以这是我对未来十年人工智能研究方向的一些想法。嗯，现在只剩下七年半了，因为已经过去两年半了。所以，如果这个项目如果成功，我们可能会在七年半内拥有达到人类智能水平的架构。马克·扎克伯格喜欢听我这么说。但我不能承诺任何事情。这个架构由这些模块组成，就是我刚才提到的那些。它们在这里以稍微不同的方式排列，更具概念性，但包括一个感知系统，一个我刚才提到的世界模型，一个执行器，它是试图找到满足多个目标的最佳动作序列的模块，以及用红色表示的目标（即成本），短期记忆，以及上方一个有点神秘的模块，叫做配置器，它实际上用于配置系统以完成特定任务，满足特定目标。我不能说我们已经构建了这个系统，但我们正在构建必要的关键模块，这些是必需的。最终，我们希望通过这种架构，能够拥有理解物理世界、具有持久记忆、能够推理和规划，并且能够通过目标和安全措施进行控制的系统。

那么，如何从感官数据中学习世界模型呢？我们总是可以尝试使用监督学习，告诉机器，现在是 T 时刻，我采取了一个动作，注意不要向左转太多，因为你驾驶的自动驾驶汽车正行驶在瑞士山脉的悬崖边，你可能会掉下悬崖。但我们当然不能标注大量的数据，来告诉系统，做这个，不要做那个，等等。所以，系统需要通过自身观察来学习世界如何运作。也许就像幼小的动物和人类婴儿一样，在生命的最初几个月里，他们很少与世界直接互动，也就是说，他们无法真正影响外部世界，但他们通过观察，学习到了大量关于世界的知识，这绝对是惊人的。不幸的是，我们缺少实现这个目标的关键组成部分。我们不会用文本来做，我们需要能够从视频中训练系统。一个迹象表明我们还没有完全成功，就是我们有 LLM 可以像律师一样通过律师资格考试。我希望这里没有太多律师……或者可以回答许多看起来很复杂的问题，但这些问题都是学习集的一部分，所以它们肯定有很强的记忆力。但我们仍然没有一个可以收拾餐桌和洗碗的家用机器人，这是一项十岁孩子可以一次学会的任务，也就是说，不需要有人教他怎么做。或者我们仍然没有，尽管埃隆·马斯克说了什么，我们仍然没有一辆可以自动驾驶的汽车，在没有人为干预的情况下，其可靠性与人类驾驶员相当。当然，也有一些存在的，但它们作弊了，也就是说，它们拥有完整的环境地图，拥有超越人类视力的传感器等等。在 Waymo、Cruise 或其他公司，但我们还没有真正意义上的自动驾驶汽车。而任何一个青少年都可以在大约二十小时的练习中学会驾驶汽车，基本上没有事故，至少肯定不会把车开下悬崖。如果那样的话，我们就没有那么多瑞士人了。而且，这不仅仅是人类，还有猫。如果你见过一只猫，甚至一只山羊，在一系列障碍物下面，规划动物如何跳跃才能到达顶部，这是相当非凡的。所以这是另一个我们称之为莫拉维克悖论的例子。

我们可以给它一个小的数字，就是今天最大的 LLM 通常用二十万亿个 token 进行训练。一个 token 就像一个单词，如果你愿意，它是一个子词。每个 token 大约是三个字节，所以它的体积大约是十的十三次方字节，一个六后面有十三个零，或者一个一后面有十四个零，为了好看。任何人类阅读这些内容都需要几十万年。这实际上是互联网上所有公开文本的总和。所以我们说这是一个惊人的信息量，但实际上我们与发展心理学家，也许是皮亚杰的继任者交谈，他们告诉我们一个四岁的孩子总共清醒了一万六千小时。这不是很多数据，一万六千小时，相当于在 YouTube 上上传三十分钟。我们有二百万根视神经纤维，每只眼睛一百万根。每根视神经纤维每秒传输大约一个字节，略少一些，但这无关紧要。所以一个四岁孩子看到的数据量大约是十的十四次方字节。与最大的 LLM 大致相同的数量级。而这一切都在四年内完成。有人告诉我们，是的，当然，视觉内容比文本更冗余。是的，这是真的，但正是冗余是必需的，因为学习系统依赖冗余来学习数据结构，世界结构。如果没有冗余，如果我们给一个学习系统随机比特，没有学习的可能性。那是不可能的。数据中没有结构。所以数据必须是冗余的才能学习。当然，视频比文本更冗余，但这是一个优势。那么，从这四年，甚至四个月的观察中，一个孩子能够在几个月内学习到关于物理世界的相当复杂的概念，主要是通过观察和一点点互动。主要是通过观察，然后孩子们能够抓取物体，操纵它们等等。所以互动更多。但孩子们学习到有生命或无生命的物体，放置的物体可以是稳定的或掉落的，物体永恒性的概念出现得非常早，可能在两个月之前，物体属于自然类别的概念，他们不需要会说话就能理解桌子和椅子是两种不同的东西，也不同。然后在大约九个月时，直觉物理学概念出现，例如重力、惯性等，所以我们有了常识，我们知道世界是如何运作的，我们知道什么是可能的，什么是不可的，在一定程度上。所以这需要很长时间，但主要是通过观察学习的。对我来说最大的问题是，如何让机器像孩子一样学习世界是如何运作的。

那么，有一个非常简单，就是自监督学习，它被用来训练 LLM，也许不是像 ChatGPT 这样的 LLM，但至少是我们用来进行翻译、仇恨言论检测或类似事情的 LLM。我们取一段文本，对这段文本进行某种形式的破坏，我们经常做的是删除某些词，改变某些词，然后训练一个大型神经网络来预测缺失的词。通过这样做，系统为了解决这个任务，会形成一种语言的内部表示，使其能够包含语义、语法、语法，总之是所有这些。这相当了不起。这种方法对于文本非常有效，对于 DNA 或蛋白质序列（即氨基酸）也有效，对于那些符号化或离散的东西。当然，一个非常自然的想法，我为此工作了大约十五年，就是对视频做同样的事情。我们拿一段视频，对其进行某种形式的破坏，然后训练一个大型神经网络来预测视频中缺失的部分。也许是视频的未来，例如。视频的延续。但这行不通。完全行不通。因为它无法预测。一段视频的未来可能发生的事情是无限的，在某种程度上。有很多事情都可能发生。如果我们训练一个系统进行预测，它预测的是所有可能发生的未来的平均值。所以它是一个模糊的图像。这正是上面小女孩身上发生的事情。这段短视频的前几帧被观察到，最后两帧被预测并且非常模糊。我们也使用了一些符号化的视频，就像下面的视频，是汽车在行驶。从左边数第二列，你会看到高速公路上的汽车在预测时都变得模糊了，因为这个问题。我们已经用我们之前提到的一些所谓的潜在变量模型找到了这个问题的部分解决方案。但实际上效果不太好。解决这个问题的新架构我称之为 JEPA。这意味着联合嵌入预测架构。它看起来是这样的。你可能会问，这和您刚才展示的有什么区别？区别在于，它不是预测视频中像素级别发生的所有事情，我们将使架构计算视频的抽象表示，包括完整的视频和损坏的视频，然后预测抽象表示。也就是说，它不会预测视频的所有像素，而是预测视频的抽象表示，我们希望它包含视频的有用信息，但会消除所有不可预测的细节。这不是一辆行驶在路上的汽车的摄像头。能够预测其他汽车、卡车、行人和自行车在路上的轨迹很重要。但预测路边树叶的运动可能不是很有用或有趣。无论如何，这是不可预测的，因为它完全是混沌的。所以我们需要一个能够构建抽象表示的系统，它能够消除我们无法预测的信息，它允许在这个抽象空间中进行预测。所以这叫做 JEPA，有一系列文章，我和 Meta 以及 NYU 的学生和研究人员一起努力让它运行起来。这里是两种架构的对比，生成式架构复制 Y，试图预测 Y，这里叫做 SY。我们取 X，计算 SX，我们取 Y，计算 SY，然后从 SX 预测 SY。对我来说，人工智能的未来是非生成式架构。今天，我们经常在媒体上将现代人工智能等同于生成式人工智能。对我来说，下一代人工智能系统将是非生成式的。

这些 JEPA 有多种风格，我不会深入细节，但最大的问题是如何训练它们。基于能量的模型这个想法真正阐明了如何训练这些系统。我们给出一系列相互兼容的 XY 示例，X 是视频的一部分，Y 是它的延续，例如。当 Y 是 X 的良好延续时，能量较低，然后必须确保如果 Y 不是 X 的良好延续，那么能量会更高。有两种方法可以做到这一点。首先，可能会发生一种现象，即这个能量函数可能会遭受所谓的“崩溃”（用法语说），也就是说，对所有人都给出零能量或相同的能量。这不是一个好模型。我们需要的是一个给出低能量的模型，我们训练的东西能量较低，但我们不训练的东西能量较高。有两种方法，对比方法和正则化方法。对比方法包括生成不兼容的 XY 对，并通过调整其参数来提高系统产生的能量。实际上，这种方法效率不高。在高维空间中，需要将能量推高的地方太多，因此无法真正扩展。所以，正则化方法是说我们将限制可以取低能量的空间体积。也就是说，当我们把一个区域的能量推低时，其余的能量必须升高，因为只有有限的区域可以取低能量。这听起来有点神秘，但我会给你一些例子。所以再次强调，这两种方法，对比方法和正则化方法。我在九十年代初就参与了它们的创造，现在我对正则化方法更加热情。

为了测试这些方法是否有效，我们训练神经网络。我们几年前做的第一个实验之一是对比式或非对比式地训练神经网络。我们给它们一对同一图像的不同版本，然后训练神经网络生成相同的表示，对于这两张图片，或者从一张图片的表示预测另一张图片的表示。所以我们有两张图片，一张有点放大，另一张有点广角，然后我们同时训练系统找到一种表示，在这种表示中我们可以进行预测，但它保留了尽可能多的输入信息。一旦编码器被训练好，我们就会使用编码器构建的表示作为分类器的输入，分类器以监督方式进行训练，我们测量该分类器在标准图像数据集上的性能。这非常有效。基于重建的方法，即生成式方法，例如自编码器、去噪自编码器、掩码自编码器、变分自编码器等，有一系列方法，效果并不那么好。表明应用于图像的生成方法不起作用。然而，基于联合嵌入的方法确实是一个很好的解决方案。我们获得了更好的结果。我不会用结果表来烦扰您，但这非常清楚。对比方法对此有效。它们可以追溯到九十年代以及二零二零年的一些最新结果，sim-clear。但这些系统产生的表示有点退化。所以我们更喜欢正则化方法，在 JEPA 架构的背景下，这意味着对编码器输出的信息内容进行某种度量，这将是学习所最小化的成本的一部分，从而最大化编码器生成的表示的信息内容。但这有一个大问题，那就是我们不知道如何最大化信息内容。我们甚至不知道如何衡量信息内容。我们可以稍微估计信息内容的上限，但我们想要的是最大化信息内容。所以我们需要的是一个下限。这样，当我们把下限推高时，信息内容也会随之升高。不幸的是，我们没有下限，只有上限。所以我们把这个上限推高，我们祈祷，如果虔诚的话，希望能最大化真实的信息内容。这确实有效。我和我的合作者已经发表了一系列文章和算法，其中一个叫做 Barlow Twins，另一个叫做 Vicreg，意思是 Variance, Invariance, Covariance, Regularization。还有一系列其他文章是 Vicreg 的变体，以及其他一些人提出了类似算法，一个叫做 MCR-Square，来自伯克利的 Yima 实验室，另一个叫做 MMCR，名字非常接近，来自我在纽约大学的神经科学同事 Su Yong Chen 和 Ryo Sumonchali。这些是基于信息内容最大化的方法，我们可以间接看到这是一种对可以取低能量的空间体积的正则化，但我不会深入细节。然后是另一组技术，我们称之为蒸馏方法。DeepMind 的同事在二零二零年提出一种方法，叫做 BYOL，Bootstrap Your Own Latent，以及我的 Meta 同事提出的其他方法，SimSiam，Dino，我与巴黎和蒙特利尔的同事合作，贡献了 iJEPA，以及视频版本 VJEPA。这些方法不是基于信息最大化，它们是基于一种系统 D，我不知道如何用英语很好地表达，一个 hack，一个 kludge。这是一个想法，出于某种神秘的原因，它试图在两个编码器之间以一种有点神秘的方式共享权重，架构层面，然后必须共享权重，然后我们只能从一侧传播梯度，然后需要应用各种各样的技巧，但最终系统在没有崩溃的情况下进行学习，也就是说，没有发生最糟糕的现象，即系统忽略输入，实际上产生恒定且相同的表示，从而解决了预测问题，但系统根本不有趣。所以它避免了崩溃，我不能完全从理论角度理解为什么，但我的 Meta 同事，Yang Dong Tian 及其合作者，Soya Ganguly 和 Shouya Ida，发表了一篇理论文章，表明最终并非如此，它之所以有效是有充分理由的等等。我并非完全理解。但它确实有效。有一种稍加改进的蒸馏方法叫做 Dino 二 ，而这种方法我们明白它为什么不会崩溃，因为它更明确一些。这是一个完全自监督训练的开源模型，您可以在此处所示的 URL 下载，它是一种通用的图像表示提取器，被世界各地许多人用于图像理解和分析。他们所做的是提取 Dino二生成的特征，然后在其之上连接另一个系统，该系统以监督方式训练，但只需要很少的数据，因为它很小，可以解决例如生物图像分割问题，找到细胞和细胞核，或者尝试从卫星图像识别某些植物等等。这非常有效，我不会用细节来烦扰您。这是一个由 Camille Coupry 完成的相当有趣的应用程序，与她在巴黎 Meta 的同事合作，旨在从极少数图像中估算冠层高度。我们当然有地球的许多卫星图像，但我们很少有已知冠层高度的标记图像。为此，需要配备激光雷达的飞机或配备激光雷达的无人机来估算高度。因此，我们没有大量数据，但我们有相对多样化的这类数据。所以卡米尔所做的是使用 Inno二 的表示，在 Inno二 之上训练一个头部，用我们从 LIDAR 获得的少量数据进行监督训练，然后将其应用于全世界。我们可以估算世界各地的冠层高度，从而推断出植被中碳的含量。这是一个非常有趣的预测量，气候变化。您看到了对气候变化有积极影响而非消极影响的人工智能应用。

那么 JEPA 的一个版本，ImageJEPA，也是一种蒸馏方法，它效果非常好，训练速度非常快，而且除了掩码之外，不需要进行所谓的数据增强。我不会用它的工作原理的细节来烦扰您，但总的来说，我们取一张图像，对其进行部分掩码，然后训练一个 JEPA 架构，从部分遮蔽的图像中预测完整图像的表示。这非常有效。它尚未完全可作为像 Dino 二 这样的通用特征提取器使用，但它是开源的，您可以像 Dino 二 一样下载该模型。然后，我们为此制作了一个视频版本，其中我们拍摄了一段视频，进行了部分遮蔽，然后训练系统，最后连接，将一个头部连接到系统提取的表示上，例如对视频中发生的动作进行分类。我们通过自监督方法获得了出色的结果，这些方法比我之前提到的重建视频的方法效果好得多。因此，我们现在有很多迹象表明，重建方法，即生成方法，不起作用。它们对幻象不起作用，对视频也不起作用，或者说它们起作用，但效果不佳。联合嵌入方法，特别是 JEPA，在法语中是“联合嵌入预测架构”。这个缩写读起来不太顺口。我不会再用所有细节来烦扰您，但这个 VJEPA 确实非常好用，实际上我们已经取得了一些初步成果，我们很快就会提交一篇论文，我们展示了 VGPA 系统，尽管它是在非常短的十六帧视频上训练的，但它具有一定的常识。如果我们给它一些可能的视频，例如一个球滚动并经过一个屏幕后面，然后我们放下屏幕，球还在那里，然后我们展示另一个几乎相同的视频，一个球滚动，停在一个屏幕后面，我们放下屏幕，球不见了，它消失了。存在一种不连续性。所以如果我们向这个系统展示成对的视频，我们要求它告诉我们这个视频的预测误差是多少，因为它能够预测视频中将会发生什么。系统地，它会告诉我们不可能的视频有一个预测误差，比可能的视频高。所以这个系统已经学会了一些现实中可能和不可能的事情。这是一个好的开始。

所以我们正在撰写并完成一篇关于它的文章。更有趣的是，我将以此结束，一个最近的模型叫做 Dino World Model。我还没有谈到它，它还没有发表，这是我第一次谈到它，所以你们是首批听众。这篇文章还没有在 Archive 上发布，但可能在一周内就会发布，作者是一位名叫 Gaoui Ejou 的学生，她由我的纽约大学机器人学同事 L'HRL Pinto 和我共同指导。高悦所做的是训练一个世界模型，一个预测器，它以行动为条件进行规划，但没有训练编码器。编码器是预训练的，实际上是基于 Dino 二 的图像表示。所以故事是这样的。我们拍摄一张图像，通过编码器，Dino二 为我们提供了该图像的表示。然后，当然，我们观察到一系列图像，这些图像对应于世界中发生的一系列动作，在这种情况下是模拟的，这是一个模拟机器人环境。我们训练一个预测器来预测 T 加一时刻世界状态的表示，该表示是 T 时刻世界表示和 T 时刻采取的动作的函数。对吗？基于这个模型，我们可以规划一个序列。此外，我们可以说，从一个特定情况开始，计算表示，然后应用我们的世界模型，带有一个我们假设的动作序列，然后我们可以测量一个成本函数，它测量最终状态和我们决定的目标状态之间的距离。目标状态我们只需通过放置目标状态的图像来计算，并通过 Inno 编码器。简单来说，就是表示空间中的欧几里得距离。然后通过优化，我们尝试找到一个最小化这个成本的动作序列。这些优化技术，我应该早点告诉您，它在幻灯片上，这就是所谓的最优控制理论中的 MPC，即模型预测控制。这完全是经典的，可以追溯到六十年代初，但传统上我们使用手动编写的模型来做这件事，我们控制的系统模型是手动编写的。而我所说的，是一个完全从数据中学习的模型。这就是它的不同之处。而且它不仅是学习的，而且是复杂的。它是一个大型神经网络，我们训练它根据当前的世界状态和动作来预测未来的世界状态。这在某些情况下效果很好，可以说，是教科书式的。我不知道为什么它会这样显示给我们。我不知道为什么它有点重叠，但是所以这里的任务，我希望我能重复。这里的任务，你看到的，不幸的是看不到左下角的例子，但这是一个叫做 Push-T 的任务，它包括推动一个 T 形的东西，用一个小点，移动它并推动它，使其到达预先确定的目标位置。你在这里看到的就是这个。也就是说……那么，还有两个例子，一个目标是规划一个小红点从墙的一侧穿过门到达另一侧的轨迹。系统必须学会它不能穿过墙壁，并且必须穿过门，规划一条轨迹。这当然是一个可以手动解决的问题，完全微不足道，但看到系统能够解决它很有趣。第二个问题稍微不那么微不足道。它包括规划机器人手臂的一系列动作，以使一根绳子变形，使其覆盖特定的形状和位置。我们已经制作了所有这些的学习示例，我们将其与其他似乎效果不佳的方法进行了比较。特别是 DeepMind 的 Danny Jha Hafner 及其合作者开发的一种名为 Dreamer V三的方法，但其效果不尽如人意。这里显示的图像是系统预测的内部表示通过单独训练的解码器生成的结果，解码器生成图像，但这个解码器不用于训练系统，它只是一个可视化技术。

好吧，这些问题有点过于简单，不太有趣。有一个稍微有趣一点的问题叫做 Granular。我希望我在演讲中保留了视频来展示它。但这真的很有趣。所以，这个任务的目标，我们桌上有一些蓝色的颗粒，位置随机，一个动作包括放下机械臂，将其移动一个 delta x，delta y，然后抬起。这是一个动作。所以是四个数字，四个值。放下机械臂的坐标，然后是 delta x，delta y，然后抬起机械臂。从随机形状中将这些蓝色颗粒放入一个正方形或另一种形状。我们尝试了几种方法，我们的方法似乎比其他方法效果好得多。我们在这里对一系列环境进行了定量测量，而不仅仅是右侧的颗粒，其中性能指标是性能衡量的是我们所说的... 查姆弗（Chamfer）在法语中怎么说？我甚至不记得了。因此，值越低越好。我们的 DinoWorldModel 方法是蓝色的，因此比 DreamerVer三、TDMPC二等其他方法效果好得多，这些方法也是强化学习，但也有世界模型。对于其他任务，但我不会深入细节。这里有一些视频展示了 PushT 和 PointMaze 的运行情况，最后您在这里右侧看到的是每次动作后的连续步骤。我将再次向您展示。每次动作后，小颗粒的配置。上面显示的是实际发生的情况，当执行这些动作时。这些动作是预先计划好的，并且以开环方式执行，也就是说，我们不看动作的结果，我们执行这五个动作，如果我没记错的话。上面显示的是这五个动作在真实模拟器中的结果。下面是系统内部模型产生的预测。所以，它相当精确。这表明 Dreamer V三相对于 Dino 效果不佳。因此，我们有了初步结果，表明这是一种规划、通过优化进行推理的故事，带有世界模型，它理解一种复杂的动力学，其中存在颗粒之间的相互作用、摩擦等，一个真正复杂的动力学，我们能够做到，即使对于我们很难手动建模的物理系统也是如此。

所以，我有一些建议。放弃生成模型，转而使用 JAPA。放弃概率模型，转而使用基于能量的模型。放弃对比方法，转而使用正则化方法。放弃强化学习，但我多年来一直这么说，目前在机器学习领域最受欢迎，所以这让我不受欢迎，但我已经习惯了。还有很多问题需要解决，才能让这些系统在大量数据下大规模运行，不仅在视频上，还在真实视频、文本、语音、代码生成和用于对话、数学以及许多其他有趣的事情。用于规划的优化算法，因为当通过大型神经网络时，优化动作序列以最小化成本并不容易，存在许多非凸性问题等。带有潜在变量的 JEPA 允许我们管理不确定性，并在存在不确定性的情况下进行规划，这有点复杂，进行分层规划。这些问题尚未解决。如果你现在开始攻读博士学位，试着研究这些问题，这真的很有趣。而且，你不会有太多竞争对手。还有其他一些我不会详细介绍的问题。所以，未来是通用的人工智能系统，助手可能在七、八、十年内达到人类智能水平，也许二十年，我们不知道，但我们希望这些进步实际上将导致未来几年出现一种新型的智能系统，人工智能系统将构成人类所有知识的存储库，也就是说，当我们想要获取知识时，不再需要去图书馆或在互联网上搜索，而是简单地询问我们的助手。这将导致一个世界，其中我们大部分的与数字世界的互动将通过人工智能助手进行。而且，无法想象这些人工智能系统将由少数位于美国西海岸的科技公司控制。对于瑞士政府，以及法国政府和美国以外的许多政府来说，公民接收到的所有数字信息都由两、三家公司控制，这是完全不可接受的。在加州或西海岸。即使这些公司意图良好，这也是对民主的威胁。因此，我们需要开源平台。这也是我一直以来大力倡导或推广人工智能开源平台的原因之一。这是为了能够实现人工智能系统的语言、文化和价值体系的多样性。在未来，如果我们真的希望 LLM，首先是 LLM，然后是更先进的人工智能系统，成为人类所有知识的真正存储库，那么这些模型的训练将必须在全球范围内进行分布式，以便在瑞士训练的模型能够理解法语。嗯，这并不太复杂，只需要纠正，理解八十和九十不是八十和九十。所以，相对于巴黎人来说，这并不太复杂。但是，他们也必须学习他们的方言。瑞士德语，它没有书面形式，所以很少有材料可以用来训练这些系统。还有欧洲各地使用的所有方言，非洲使用的两千种语言，印度使用的一千五百种左右的语言，印度已经有二十二种官方语言。印度尼西亚有七百种语言。还有所有没有书面形式的语言。世界上没有书面形式的语言比有书面形式的语言多。为此，这些系统的学习必须在全球范围内进行分布式，以便在印度，我们可以训练印度语言。但最终，我们拥有一个有点共同的系统，也就是说，它具有全世界的共同智能。所以，开源对于这个未来是必要的。然后还需要研究这些安全措施等问题。那么，开源的问题在于，有些人认为人工智能系统本质上是危险的，因此需要规范人工智能的研究和开发，并规范人工智能系统的分发，特别是开源系统。这会扼杀开源。对于像 Meta 这样的公司来说，以开源方式分发模型是不值得的，如果存在任何法规告诉我们它太危险的风险。所以法规，特别是在欧洲，可能会扼杀开源。欧洲各国政府，而不是欧洲联盟政府，而是欧洲各国政府，非常清楚通往主权的道路，欧洲人工智能的发展需要通过开源，因此他们正在与欧盟抗争。这有点像卡夫卡式的。我就到这里。非常感谢。