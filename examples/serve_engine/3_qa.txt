[SPEAKER0] 我想有麦克风在传递。我要感谢 Yann 的这次非常有趣和富有远见的演讲。我们还有一些时间提问。请不要犹豫，抓住这个机会提问。

[SPEAKER1] 谢谢您的演讲。您刚才提到了平台。您对基础设施问题有什么看法？是非常商品化的东西，还是比现在更加去中心化？

[SPEAKER2] 我想您指的是计算基础设施,或者仅仅是为了微调一个大型模型，都需要相当大的计算中心。通常，Meta 使用的一个有点可还原的数量是一万六千个 GPU 集群。问题是，一个一万六千个 GPU 的集群，首先它要花费十亿欧元、瑞士法郎或美元，这是第一点，而且它消耗大量的能源，大约吉瓦级。因此，必须将这些计算中心设在能源不仅价格低廉，而且是脱碳的国家。这意味着法国，因为有核能；瑞士，因为有水力发电；魁北克，因为有水力发电；或者哥斯达黎加，因为有水力发电。但还有其他问题。还有一些其他国家自然也是如此。但我们不能使用，例如，纯太阳能或风能，因为当没有阳光或风时，机器也必须运转，而我们目前无法以所需规模储存能源。因此，许多关心人工智能未来的人士都在谈论简单地在核电站旁边建立计算中心。这样可以避免能源传输过程中的能量损失。

[SPEAKER3] 谢谢您的演讲。我有一个非常技术性的问题。您认为信息论现在能否帮助我们创建一种新的模型训练形式？因为您提到了信息论，比如“大量信息”，诸如此类。您认为这可能吗？

[SPEAKER2] 先验分布用于正则化估计，这完全是任意的。所以实际上我们没有办法做到这一点，我们没有办法可靠地估计依赖关系，尤其是在高维空间中。所以它可以解决一些问题，也就是说推导出一些一般性的性质，但在实践中并不能真正将其简化为一种实用的算法。话虽如此，我有一位优秀的博士后与我合作，名叫 Ravid Chouardziv，他是信息论专家，并就信息论在通过信息最大化进行 SSL 训练等方面的适用性撰写了一系列文章。

[SPEAKER4] 非常感谢您的演讲，这真的很有启发性。我想问，如果我理解正确的话，基于 JEPA 的系统，在图像和视频方面表现优异。有没有证据表明它们在语言相关任务方面也表现优异？您如何解释这些如此简单的、概率性的、生成式的模型能够拥有这些似乎能够推理的涌现能力，即使它们根据您的定义确实无法真正推理。

[SPEAKER2] 问题是，我们还不知道，但我们至少有两个关于这方面的项目，一个是将 JPA 用于文本，另一个是将 JPA 用于代码，即代码编写。代码编写，显然我们可以完全自动地编写代码，所以我们训练一个 LLM，然后进行一些微调，但最终当我们编写一个复杂的程序或软件系统时，我们必须进行一些规划，包括分层规划，包括数据结构等。这是当前代码生成系统无法做到的。所以，我们正在研究这个问题。我目前还不能给出结果。哦，对了，还有第二个问题。关于为什么……为什么……是的，就是这样。所以，那些我们称之为“仅解码器”的模型，也就是纯解码器架构的性能，GPT。为什么当我们在大量数据上训练它们时，它们表现得如此出色？是的，这相当令人惊叹，当然，但这本质上是反刍。也就是说，最好的例子之一是，我们问一个学生，无论他是谁，给出我们给孩子的一个小谜题的解决方案。我们有一只狼、一只山羊和一颗白菜在河的一边，我们有一艘船一次只能运载两件物品，当然，狼想吃山羊，而它想吃白菜，我们怎么做？我们先运山羊，狼不会吃白菜，然后我们运白菜，但我们必须把山羊带回来，否则它会吃白菜，然后我们运狼，最后我们运山羊。然后，由于所有人都受到监督，所以没有问题。所以我们将这个问题交给 GPT，它当然能很好地解决。但这只是因为这个问题的解决方案在互联网上无处不在，所以系统只是死记硬背了。然后我们稍微改变一下问题的数据，我们告诉它，不，只有一只狼和一颗白菜。它给我们同样的解决方案，需要三次往返。实际上，它并没有理解，没有那种世界的心理模型，即当你从一边到另一边时，你就不再在第一边了，你只在第二边，一个物体不能同时存在于两个地方，而且狼不吃白菜等等。总之，所有这些知识实际上都不存在于这些 LLM 中。自从这种批评被提出以来，构建 LLM 的人已经包含了这个问题的所有可能的变体，并训练系统正确回答。几年前有过类似的事情，有人问我，是一位纽约大学的哲学同事问我，有没有 LLM 无法解决的问题？我说，这很简单，那已经是几年前了，我说，想象有七个齿轮，它们都安装在轴上，每个齿轮都与前面和后面的齿轮啮合。现在我们顺时针转动二号齿轮。七号齿轮会怎么转？LLM 无法回答。因为它太复杂了，需要一系列它们无法进行的推理，并且拥有一个心理模型等等。几个月后，这个讨论在 Twitter 上公开了。几个月后，有人告诉我，实际上，这个问题现在很容易被 LLM 解决。但这实际上是因为 LLM 已经用 Twitter 进行了训练。所以问题，当然，解决方案就在那里，所有人都谈论过等等。所以同一位哲学家问我，想象一个当前的 LLM 无法解决的另一个问题。我告诉他，这很简单，你把这七个齿轮放在一个圆圈上。它们都与相邻的两个齿轮啮合。现在，试着顺时针转动二号齿轮。七号齿轮会怎么转？系统会像它们在一条线上一样操作。当然，这是不可能的，这是一个陷阱。当齿轮数量为奇数时，如果你试图转动其中一个，它不会转动，这是不可能的，它们卡住了。当然，LLM 根本不知道。所以显然，很多人也无法解决这个问题，但假设他们足够思考，他们可以解决。有很多这样的问题需要一种心理图像，一种心理模型，而 LLM 无法做到，除非它们直接用答案进行训练。

[SPEAKER0] 非常感谢。不幸的是，我们必须结束了。今天我还要再次感谢 Yann。并邀请您下次带着 IGP二或三模型再次光临。非常感谢。